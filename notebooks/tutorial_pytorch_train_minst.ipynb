{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch reference, for training vision functions, on a simpler dataset MINST."
      ],
      "metadata": {
        "id": "PlHr2aNrA2SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "TqKJmbF2Oh4H",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom packages that need to be installed separately.\n",
        " - torchinfo, shows the structure of neural network\n",
        " - torchmetrics, implements certain metrics out of the box\n"
      ],
      "metadata": {
        "id": "kvbnztuwD-n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "!pip install torchmetrics\n",
        "\n",
        "from torchinfo import summary\n",
        "from torchmetrics import Accuracy"
      ],
      "metadata": {
        "id": "ufLuTyrYD784"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "finish this tutorial:\n",
        "\n",
        "https://medium.com/@deepeshdeepakdd2/lenet-5-implementation-on-mnist-in-pytorch-c6f2ee306e37\n"
      ],
      "metadata": {
        "id": "WJRMOTiXROBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison between Torch and FastAi concepts**"
      ],
      "metadata": {
        "id": "wHjTw7NbPYXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch's Dataset and DataLoader are indeed similar  in concept to fastai's DataBlock and DataLoader,\n",
        "but there are some key differences in how they are used and what they provide.\n",
        "\n",
        "In essence, fastai's DataBlock and DataLoader can be seen as a more opinionated and user-friendly wrapper around PyTorch's Dataset and DataLoader, providing a streamlined way to prepare data for deep learning models.\n"
      ],
      "metadata": {
        "id": "ZrjrYwthjLb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FastAI DataBlock vs PyTorch Dataset:**\n",
        "\n",
        "**TODO write**"
      ],
      "metadata": {
        "id": "lLlkjdITkSXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FastAI DataLoader vs PyTorch DataLoader:**\n",
        "\n",
        "In both libraries this class wraps a Dataset/Datablock and provides an iterable over the it. It handles batching, shuffling, and parallel loading of data.\n",
        "\n",
        "FastAI DataLoader is built on top of PyTorch's DataLoader and adds more features, such as transformations applied on the GPU and progress bars."
      ],
      "metadata": {
        "id": "dy1eaZ3Wnz_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch   .view():\n",
        "\n",
        "In PyTorch, when you use .view() to reshape a tensor, the parameter -1 is a placeholder that tells PyTorch to automatically infer the size of that dimension.\n",
        ".view(-1) means that tensor will be reshaped to single dimension tensor only one dimension can be infered, be -1:\n",
        "\n",
        "```\n",
        "flattened_image = image.view(-1)\n",
        "```\n",
        "\n",
        "\n",
        ".view() is generally memory-efficient because it avoids data copies,\n",
        "but be mindful of memory contiguity for optimal performance.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "InayN1-6QuLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mean_and_std_formula(dataset):\n",
        "  total_pixels_count = 0\n",
        "  sum_pixels = 0\n",
        "\n",
        "  # _ is the label in data\n",
        "  for image, _ in dataset:\n",
        "      flattened_image = image.view(-1)\n",
        "      sum_pixels += flattened_image.sum()\n",
        "      total_pixels_count += flattened_image.numel()\n",
        "  mean = sum_pixels / total_pixels_count\n",
        "\n",
        "  sum_sq_diff = 0\n",
        "  for image, _ in dataset:\n",
        "      sq_diff = (image.view(-1) - mean) ** 2\n",
        "      sum_sq_diff += sq_diff.sum()\n",
        "\n",
        "  variance = sum_sq_diff / total_pixels_count\n",
        "  std_dev = torch.sqrt(variance)\n",
        "  return {'mean': mean.item(), 'std_dev': std_dev.item()}"
      ],
      "metadata": {
        "id": "D5EeE2LTB5eJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch you can get a single Python number from a PyTorch tensor containing a single value by using the .item() method.\n",
        "\n",
        "torch.stack:  concatenates a sequence of tensors along a new dimension.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VvQhp2L-3BX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mean_and_std(dataset):\n",
        "  imgs = torch.stack([img for img, _ in dataset], dim=0)\n",
        "  return {'mean': imgs.mean().item(), 'std_dev': imgs.std().item()}"
      ],
      "metadata": {
        "id": "WYafIM1q2mzf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_mean_and_std(torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.ToTensor()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok8mnwPm3KoI",
        "outputId": "c2b6fef7-a1be-4742-b7e7-5107bd335417"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean': 0.13066047430038452, 'std_dev': 0.30810782313346863}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_mean_and_std_formula(torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.ToTensor()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH2BKMsL3gZs",
        "outputId": "fac90f8c-6902-4b38-e4c1-037e86fcfeac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean': 0.13066048920154572, 'std_dev': 0.308107852935791}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training of the dataset:"
      ],
      "metadata": {
        "id": "wjfic9j34xO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset =  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,)),\n",
        "                             ])),"
      ],
      "metadata": {
        "id": "feKczW3r42Gl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset)"
      ],
      "metadata": {
        "id": "DOeZudY145qr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description of PyTorch nn classes:**\n",
        "\n",
        "**nn.Module**\n",
        "\n",
        "is the base class for all neural network modules. It provides a framework for building and managing neural network layers and models.\n",
        "\n",
        "You need to implement all the layers in costructor:\n",
        "\n",
        "`def __init__(self):`\n",
        "\n",
        "the forward method, that implements the forward pass in neural network.\n",
        "\n",
        "`def forward(self, x):`\n",
        "\n",
        "\n",
        "\n",
        "**nn.Sequential**\n",
        "\n",
        "is a container module that stacks other modules (like layers such as convolutional layers, activation functions, pooling layers, etc.) in a specific sequential order.\n",
        "It ensures that the input is passed through each module in the sequence, and the output of one module becomes the input for the next\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p8oHomxRxu_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LeNet-5 neural network:\n",
        "\n",
        "\n",
        "TODO, add reference for lenet5 images, explain padding for 28 input, copy code from reference title\n",
        "\n",
        "\n",
        "Max pooling is used instead of average pooling, because\n",
        "MNIST digits dataset using CNN, max pooling is used because the background in these images is made black with white foreground.\n",
        "\n",
        "[reference article](https://medium.com/@bdhuma/which-pooling-method-is-better-maxpooling-vs-minpooling-vs-average-pooling-95fb03f45a9\n",
        ")\n",
        "\n",
        "architecture:\n",
        "\n",
        "https://medium.com/@siddheshb008/lenet-5-architecture-explained-3b559cb2d52b\n",
        "\n",
        "https://www.geeksforgeeks.org/computer-vision/lenet-5-architecture/\n"
      ],
      "metadata": {
        "id": "RzSL9FW75Iqo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "https://medium.com/@benjybo7/7-pytorch-pool-methods-you-should-be-using-495eb00325d6\n"
      ],
      "metadata": {
        "id": "mE9WTBnWSGwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet5Variant(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.feature = nn.Sequential(\n",
        "            #1\n",
        "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),   # 28*28->32*32-->28*28\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 14*14\n",
        "\n",
        "            #2\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),  # 10*10\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 5*5\n",
        "\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=16*5*5, out_features=120),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=120, out_features=84),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=84, out_features=10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.classifier(self.feature(x))\n"
      ],
      "metadata": {
        "id": "xn8hy6y746YH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model summary output, with this you can also test if structure of network is correct. If operations don't match error will be thrown\n"
      ],
      "metadata": {
        "id": "McI_42PK1KrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_test = LeNet5Variant()\n",
        "summary(model=model_test, input_size=(1, 1, 28, 28), col_width=20,\n",
        "                  col_names=['input_size', 'output_size', 'num_params', 'trainable'], row_settings=['var_names'], verbose=0)"
      ],
      "metadata": {
        "id": "L573Xtfry5bT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ed4d270-0f1e-42cd-d1e4-151c5ed06f8f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "========================================================================================================================\n",
              "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
              "========================================================================================================================\n",
              "LeNet5Variant (LeNet5Variant)            [1, 1, 28, 28]       [1, 10]              --                   True\n",
              "├─Sequential (feature)                   [1, 1, 28, 28]       [1, 16, 5, 5]        --                   True\n",
              "│    └─Conv2d (0)                        [1, 1, 28, 28]       [1, 6, 28, 28]       156                  True\n",
              "│    └─Tanh (1)                          [1, 6, 28, 28]       [1, 6, 28, 28]       --                   --\n",
              "│    └─MaxPool2d (2)                     [1, 6, 28, 28]       [1, 6, 14, 14]       --                   --\n",
              "│    └─Conv2d (3)                        [1, 6, 14, 14]       [1, 16, 10, 10]      2,416                True\n",
              "│    └─Tanh (4)                          [1, 16, 10, 10]      [1, 16, 10, 10]      --                   --\n",
              "│    └─MaxPool2d (5)                     [1, 16, 10, 10]      [1, 16, 5, 5]        --                   --\n",
              "├─Sequential (classifier)                [1, 16, 5, 5]        [1, 10]              --                   True\n",
              "│    └─Flatten (0)                       [1, 16, 5, 5]        [1, 400]             --                   --\n",
              "│    └─Linear (1)                        [1, 400]             [1, 120]             48,120               True\n",
              "│    └─Tanh (2)                          [1, 120]             [1, 120]             --                   --\n",
              "│    └─Linear (3)                        [1, 120]             [1, 84]              10,164               True\n",
              "│    └─Tanh (4)                          [1, 84]              [1, 84]              --                   --\n",
              "│    └─Linear (5)                        [1, 84]              [1, 10]              850                  True\n",
              "========================================================================================================================\n",
              "Total params: 61,706\n",
              "Trainable params: 61,706\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.42\n",
              "========================================================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.05\n",
              "Params size (MB): 0.25\n",
              "Estimated Total Size (MB): 0.30\n",
              "========================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset MNIST doesn't come with validation part out of the box.\n",
        "Here a split is performed where 10% is assigned to validation"
      ],
      "metadata": {
        "id": "XfX7dQb8LGGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_RATIO =  0.9\n",
        "BATCH_SIZE = 32\n",
        "generator = torch.Generator().manual_seed(42)"
      ],
      "metadata": {
        "id": "PXAISeXkMtza"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_dataset = torchvision.datasets.MNIST(root=\"/files/\", train=True, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root=\"/files/\", train=False, download=True)\n",
        "\n",
        "train_size = int(TRAIN_RATIO * len(train_val_dataset))\n",
        "val_size = len(train_val_dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset=train_val_dataset, lengths=[train_size, val_size], generator=generator)\n",
        "len(train_dataset), len(val_dataset), len(test_dataset)"
      ],
      "metadata": {
        "id": "4XM55O31VKuv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05b20175-b5cf-48b8-fc69-ad3e6f704c73"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54000, 6000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u3X5-MHANNY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# This are determined by the batch size parameter\n",
        "len(train_dataloader), len(val_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUGyBgjwNUGM",
        "outputId": "f127c9d5-4774-482f-bae0-ebbfb90b007e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1688, 188, 313)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}