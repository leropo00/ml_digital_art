{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5c91ff35ad344fbe807b15052b2ad926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df955edc136a4fc18b91557be8e0746a",
              "IPY_MODEL_4d569a2716f24b62aa7a7ffd3606bcbd",
              "IPY_MODEL_5e579dd76c47463a8977dd791bd8d293"
            ],
            "layout": "IPY_MODEL_312985adbd794f8d9f6f0ab2f4b8e771"
          }
        },
        "df955edc136a4fc18b91557be8e0746a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6de294ca8ec9406fa989ec45561d2dae",
            "placeholder": "​",
            "style": "IPY_MODEL_d88755a344fe462abde7ef965b717cf5",
            "value": "100%"
          }
        },
        "4d569a2716f24b62aa7a7ffd3606bcbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5955e19c593941628490b242d53472e6",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf954290692b4cfd9ab744aa7ed62df7",
            "value": 12
          }
        },
        "5e579dd76c47463a8977dd791bd8d293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dffa0e80e69d4ba9ad1fb581b3c28ec8",
            "placeholder": "​",
            "style": "IPY_MODEL_a047d8b8272d477dacce998ea7f0e7f2",
            "value": " 12/12 [03:55&lt;00:00, 19.28s/it]"
          }
        },
        "312985adbd794f8d9f6f0ab2f4b8e771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de294ca8ec9406fa989ec45561d2dae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d88755a344fe462abde7ef965b717cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5955e19c593941628490b242d53472e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf954290692b4cfd9ab744aa7ed62df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dffa0e80e69d4ba9ad1fb581b3c28ec8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a047d8b8272d477dacce998ea7f0e7f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch reference, for training vision functions, on a simpler dataset MINST."
      ],
      "metadata": {
        "id": "PlHr2aNrA2SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "TqKJmbF2Oh4H",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import os\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "Es1rCpNHJuk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO, ideas to add\n",
        "earlystopping, learning rate finder, most confused, captum model interpretation, simpler loss plot"
      ],
      "metadata": {
        "id": "XwZFVbvow7Q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom packages that need to be installed separately.\n",
        " - torchinfo, shows the structure of neural network\n",
        " - torchmetrics, implements certain metrics out of the box\n"
      ],
      "metadata": {
        "id": "kvbnztuwD-n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "!pip install torchmetrics\n",
        "\n",
        "from torchinfo import summary\n",
        "from torchmetrics import Accuracy"
      ],
      "metadata": {
        "id": "ufLuTyrYD784"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "finish this tutorial:\n",
        "\n",
        "https://medium.com/@deepeshdeepakdd2/lenet-5-implementation-on-mnist-in-pytorch-c6f2ee306e37\n"
      ],
      "metadata": {
        "id": "WJRMOTiXROBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison between Torch and FastAi concepts**"
      ],
      "metadata": {
        "id": "wHjTw7NbPYXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch's Dataset and DataLoader are indeed similar  in concept to fastai's DataBlock and DataLoader,\n",
        "but there are some key differences in how they are used and what they provide.\n",
        "\n",
        "In essence, fastai's DataBlock and DataLoader can be seen as a more opinionated and user-friendly wrapper around PyTorch's Dataset and DataLoader, providing a streamlined way to prepare data for deep learning models.\n"
      ],
      "metadata": {
        "id": "ZrjrYwthjLb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FastAI DataBlock vs PyTorch Dataset:**\n",
        "\n",
        "\n",
        "- Pytorch Dataset:\tThis is an abstract class that represents a dataset. You need to create a custom class that inherits from Dataset and implements the __len__ and __getitem__ methods.\t__len__ should return the size of the dataset, and __getitem__ should return a sample (data and label) given an index.\n",
        "\n",
        "- Fastai  DataBlock:\tThis is a high-level API that simplifies the process of creating datasets and dataloaders. It allows you to define the structure of your data, how to get the items, how to split the data into training and validation sets, how to apply transformations, and how to create the dataloaders. It encapsulates many steps that you would typically do manually with PyTorch Dataset and DataLoader.\n",
        "\n",
        "Both represent the dataset, one is more opiniated than the other:\n",
        "\n",
        "- Level of Abstraction: Fastai's DataBlock provides a much higher level of abstraction compared to PyTorch's Dataset.\tWith DataBlock, you define the data pipeline declaratively, while with PyTorch Dataset, you implement the data loading logic imperatively.\n",
        "\n",
        "- Flexibility: PyTorch's Dataset is more flexible if you need to implement very custom data loading logic that is not easily expressed with DataBlock.\n",
        "\n",
        "- Ease of Use: Fastai's DataBlock is generally easier to use for common deep learning tasks, as it handles many of the details for you.\n"
      ],
      "metadata": {
        "id": "lLlkjdITkSXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FastAI DataLoader vs PyTorch DataLoader:**\n",
        "\n",
        "In both libraries this class wraps a Dataset/Datablock and provides an iterable over the it. It handles batching, shuffling, and parallel loading of data.\n",
        "\n",
        "FastAI DataLoader is built on top of PyTorch's DataLoader and adds more features, such as transformations applied on the GPU and progress bars."
      ],
      "metadata": {
        "id": "dy1eaZ3Wnz_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch   .view():\n",
        "\n",
        "In PyTorch, when you use .view() to reshape a tensor, the parameter -1 is a placeholder that tells PyTorch to automatically infer the size of that dimension.\n",
        ".view(-1) means that tensor will be reshaped to single dimension tensor only one dimension can be infered, be -1:\n",
        "\n",
        "```\n",
        "flattened_image = image.view(-1)\n",
        "```\n",
        "\n",
        "\n",
        ".view() is generally memory-efficient because it avoids data copies,\n",
        "but be mindful of memory contiguity for optimal performance.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "InayN1-6QuLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mean_and_std_formula(dataset):\n",
        "  total_pixels_count = 0\n",
        "  sum_pixels = 0\n",
        "\n",
        "  # _ is the label in data\n",
        "  for image, _ in dataset:\n",
        "      flattened_image = image.view(-1)\n",
        "      sum_pixels += flattened_image.sum()\n",
        "      total_pixels_count += flattened_image.numel()\n",
        "  mean = sum_pixels / total_pixels_count\n",
        "\n",
        "  sum_sq_diff = 0\n",
        "  for image, _ in dataset:\n",
        "      sq_diff = (image.view(-1) - mean) ** 2\n",
        "      sum_sq_diff += sq_diff.sum()\n",
        "\n",
        "  variance = sum_sq_diff / total_pixels_count\n",
        "  std_dev = torch.sqrt(variance)\n",
        "  return {'mean': mean.item(), 'std_dev': std_dev.item()}"
      ],
      "metadata": {
        "id": "D5EeE2LTB5eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch you can get a single Python number from a PyTorch tensor containing a single value by using the .item() method.\n",
        "\n",
        "torch.stack:  concatenates a sequence of tensors along a new dimension.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VvQhp2L-3BX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mean_and_std(dataset):\n",
        "  imgs = torch.stack([img for img, _ in dataset], dim=0)\n",
        "  return {'mean': imgs.mean().item(), 'std_dev': imgs.std().item()}"
      ],
      "metadata": {
        "id": "WYafIM1q2mzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_mean_and_std(torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.ToTensor()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok8mnwPm3KoI",
        "outputId": "ab38186b-5f54-4db5-c41e-9eecd45dfa9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean': 0.13066047430038452, 'std_dev': 0.30810782313346863}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_mean_and_std_formula(torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.ToTensor()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH2BKMsL3gZs",
        "outputId": "37e1a8e9-0384-490b-a65f-cdd175d3d9e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean': 0.13066048920154572, 'std_dev': 0.308107852935791}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training of the dataset:"
      ],
      "metadata": {
        "id": "wjfic9j34xO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset =  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,)),\n",
        "                             ])),"
      ],
      "metadata": {
        "id": "feKczW3r42Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset)"
      ],
      "metadata": {
        "id": "DOeZudY145qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description of PyTorch nn classes:**\n",
        "\n",
        "**nn.Module**\n",
        "\n",
        "is the base class for all neural network modules. It provides a framework for building and managing neural network layers and models.\n",
        "\n",
        "You need to implement all the layers in costructor:\n",
        "\n",
        "`def __init__(self):`\n",
        "\n",
        "the forward method, that implements the forward pass in neural network.\n",
        "\n",
        "`def forward(self, x):`\n",
        "\n",
        "\n",
        "\n",
        "**nn.Sequential**\n",
        "\n",
        "is a container module that stacks other modules (like layers such as convolutional layers, activation functions, pooling layers, etc.) in a specific sequential order.\n",
        "It ensures that the input is passed through each module in the sequence, and the output of one module becomes the input for the next\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p8oHomxRxu_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LeNet-5 neural network:\n",
        "\n",
        "\n",
        "Padding of 2 is added on first layer, since input images here have size 28x28.\n",
        "From here https://github.com/torch/tutorials/issues/48:\n",
        "The MNIST dataset contains vectorized images of 28X28. Therefore we define a new function to reshape each batch of MNIST images to 28X28 and then resize to 32X32. The reason of resizing to 32X32 is to make it a power of two and therefore we can easily use the stride of 2 for downsampling and upsampling.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Max pooling is used instead of average pooling, because\n",
        "MNIST digits dataset using CNN, max pooling is used because the background in these images is made black with white foreground.\n",
        "\n",
        "[reference article](https://medium.com/@bdhuma/which-pooling-method-is-better-maxpooling-vs-minpooling-vs-average-pooling-95fb03f45a9\n",
        ")\n",
        "\n",
        "architecture:\n",
        "\n",
        "https://medium.com/@siddheshb008/lenet-5-architecture-explained-3b559cb2d52b\n",
        "\n",
        "https://www.geeksforgeeks.org/computer-vision/lenet-5-architecture/"
      ],
      "metadata": {
        "id": "RzSL9FW75Iqo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "![original_lenet5_diagran.webp](data:image/webp;base64,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)"
      ],
      "metadata": {
        "id": "O3VYcANjj56V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pooling methods in PyTorch:\n",
        "\n",
        "https://medium.com/@benjybo7/7-pytorch-pool-methods-you-should-be-using-495eb00325d6\n"
      ],
      "metadata": {
        "id": "mE9WTBnWSGwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet5Variant(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.feature = nn.Sequential(\n",
        "            #1\n",
        "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),   # 28*28->32*32-->28*28\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 14*14\n",
        "\n",
        "            #2\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),  # 10*10\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 5*5\n",
        "\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            # transforms extracted features into single tensor\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=16*5*5, out_features=120),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=120, out_features=84),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=84, out_features=10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.classifier(self.feature(x))\n"
      ],
      "metadata": {
        "id": "xn8hy6y746YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why are same layers called feature and some classifier:\n",
        "\n",
        "- Feature layers are layers that extract features:\n",
        "\n",
        "   Convolutional and Pooling Layers: These layers process the input image, extracting spatial hierarchies of features. The output of the last pooling layer is usually a flattened tensor (a one-dimensional array) representing the features.\n",
        "\n",
        "\n",
        "-  Classifier layers, are layers that then classifiy this features:\n",
        "   \n",
        "   Fully Connected Layers receive flattened tensor as input from feature extractor, that is then passed to one or more fully connected layers.   In these layers, every neuron is connected to every neuron in the previous layer, just like in a standard neural network. These layers learn non-linear combinations of the extracted features.\n",
        "\n",
        "Essentially, the convolutional and pooling layers act as feature extractors, and the fully connected layers act as classifiers that use those extracted features to make a decision.\n"
      ],
      "metadata": {
        "id": "ohWG4gaHWN2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model summary output, with this you can also test if structure of network is correct. If operations don't match error will be thrown\n"
      ],
      "metadata": {
        "id": "McI_42PK1KrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_lenet5 = LeNet5Variant()\n",
        "summary(model=model_lenet5, input_size=(1, 1, 28, 28), col_width=20,\n",
        "                  col_names=['input_size', 'output_size', 'num_params', 'trainable'], row_settings=['var_names'], verbose=0)"
      ],
      "metadata": {
        "id": "L573Xtfry5bT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8670f54-f1e6-40d9-9278-24769e8118a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "========================================================================================================================\n",
              "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
              "========================================================================================================================\n",
              "LeNet5Variant (LeNet5Variant)            [1, 1, 28, 28]       [1, 10]              --                   True\n",
              "├─Sequential (feature)                   [1, 1, 28, 28]       [1, 16, 5, 5]        --                   True\n",
              "│    └─Conv2d (0)                        [1, 1, 28, 28]       [1, 6, 28, 28]       156                  True\n",
              "│    └─Tanh (1)                          [1, 6, 28, 28]       [1, 6, 28, 28]       --                   --\n",
              "│    └─MaxPool2d (2)                     [1, 6, 28, 28]       [1, 6, 14, 14]       --                   --\n",
              "│    └─Conv2d (3)                        [1, 6, 14, 14]       [1, 16, 10, 10]      2,416                True\n",
              "│    └─Tanh (4)                          [1, 16, 10, 10]      [1, 16, 10, 10]      --                   --\n",
              "│    └─MaxPool2d (5)                     [1, 16, 10, 10]      [1, 16, 5, 5]        --                   --\n",
              "├─Sequential (classifier)                [1, 16, 5, 5]        [1, 10]              --                   True\n",
              "│    └─Flatten (0)                       [1, 16, 5, 5]        [1, 400]             --                   --\n",
              "│    └─Linear (1)                        [1, 400]             [1, 120]             48,120               True\n",
              "│    └─Tanh (2)                          [1, 120]             [1, 120]             --                   --\n",
              "│    └─Linear (3)                        [1, 120]             [1, 84]              10,164               True\n",
              "│    └─Tanh (4)                          [1, 84]              [1, 84]              --                   --\n",
              "│    └─Linear (5)                        [1, 84]              [1, 10]              850                  True\n",
              "========================================================================================================================\n",
              "Total params: 61,706\n",
              "Trainable params: 61,706\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.42\n",
              "========================================================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.05\n",
              "Params size (MB): 0.25\n",
              "Estimated Total Size (MB): 0.30\n",
              "========================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset MNIST doesn't come with validation part out of the box.\n",
        "Here a split is performed where 10% is assigned to validation"
      ],
      "metadata": {
        "id": "XfX7dQb8LGGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_RATIO =  0.9\n",
        "BATCH_SIZE = 32\n",
        "generator = torch.Generator().manual_seed(42)"
      ],
      "metadata": {
        "id": "PXAISeXkMtza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,)),\n",
        "                             ])\n",
        "train_val_dataset = torchvision.datasets.MNIST(root=\"/files/\", train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root=\"/files/\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_size = int(TRAIN_RATIO * len(train_val_dataset))\n",
        "val_size = len(train_val_dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset=train_val_dataset, lengths=[train_size, val_size], generator=generator)\n",
        "len(train_dataset), len(val_dataset), len(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1GPG1zBQd9K",
        "outputId": "05511904-5cbe-42b6-deec-ab94f77123e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54000, 6000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False) # No need to shuffle validation data\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False) # No need to shuffle test data\n",
        "\n",
        "\n",
        "# This are determined by the batch size parameter\n",
        "len(train_dataloader), len(val_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkJhgmawQo_7",
        "outputId": "9afb49fc-4924-4bb3-9abb-fa40adbd7763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1688, 188, 313)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u3X5-MHANNY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch model train vs eval, are two different of operation for training vs interference:\n",
        "\n",
        "Here's what model.train() does:\n",
        "\n",
        "- Dropout Layers: When the model is in training mode, dropout layers are active. They randomly drop out a certain percentage of neurons to prevent overfitting.\n",
        "- Batch Normalization Layers: In training mode, batch normalization layers calculate and update the running mean and variance of the input data for each batch. These running statistics are used during evaluation.\n",
        "\n",
        "\n",
        "In contrast, model.eval() sets the model to evaluation mode:\n",
        "\n",
        "- Dropout Layers: Dropout layers are inactive in evaluation mode. All neurons are used.\n",
        "- Batch Normalization Layers: Batch normalization layers use the accumulated running mean and variance from the training phase instead of calculating them on the current batch.\n"
      ],
      "metadata": {
        "id": "k36cTXjR5GCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE_USED = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "EPOCHS_COUNT = 12\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_lenet5.parameters(), lr=LEARNING_RATE)\n",
        "accuracy = Accuracy(task='multiclass', num_classes=10)"
      ],
      "metadata": {
        "id": "uM-kEtXKGLKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training loop with validation**"
      ],
      "metadata": {
        "id": "xdm5h20tLOtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LOGGING_DIRECTORY = os.path.join(\"MNIST_lenet5\", datetime.now().strftime(\"%Y-%m-%d\"))\n",
        "writer = SummaryWriter(LOGGING_DIRECTORY)\n",
        "\n",
        "accuracy = accuracy.to(DEVICE_USED)\n",
        "model_lenet5 = model_lenet5.to(DEVICE_USED)\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS_COUNT)):\n",
        "    #### Training loop\n",
        "\n",
        "    # set model to training stage\n",
        "    model_lenet5.train()\n",
        "    train_loss_sum, train_accuracy_sum = 0.0, 0.0\n",
        "    for X, y in train_dataloader:\n",
        "        X, y = X.to(DEVICE_USED), y.to(DEVICE_USED)\n",
        "        y_pred = model_lenet5(X)\n",
        "\n",
        "        # first argument is the predicted, second is the actual value\n",
        "        current_loss = loss_fn(y_pred, y)\n",
        "        train_loss_sum += loss_fn(y_pred, y).item()\n",
        "        train_accuracy_sum += accuracy(y_pred, y)\n",
        "\n",
        "        # 1.) clear out the gradient that accumulated so far\n",
        "        # PyTorch accumulates the gradients on each subsequent backward passes\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 2.) performs backpropagation, calculating the gradients of the loss\n",
        "        # with respect to all the model's parameters that have requires_grad=True.\n",
        "        # These gradients are stored in the .grad attribute of each parameter tensor\n",
        "        # current_loss is as tensor, torch.Tensor.backward calculated the gradient\n",
        "        current_loss.backward()\n",
        "\n",
        "        # 3.) update the weights according to calcualted gradient, based on optimization algorithm(SGD, ADAM)\n",
        "        optimizer.step()\n",
        "\n",
        "    # losses are calcualted for each batch separately, calculate average loss, accuracy\n",
        "    train_loss      = train_loss_sum / len(train_dataloader)\n",
        "    train_accuracy  = train_accuracy_sum / len(train_dataloader)\n",
        "\n",
        "    #### Validation loop\n",
        "\n",
        "    # set model to prediction stage, inference\n",
        "    model_lenet5.eval()\n",
        "    # context manager that is used to temporarily disable gradient calculation\n",
        "    # there is no need to reenable gradient calculation, after with block finishes\n",
        "\n",
        "    validation_loss_sum, validation_accuracy_sum = 0.0, 0.0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for X, y in val_dataloader:\n",
        "            X, y = X.to(DEVICE_USED), y.to(DEVICE_USED)\n",
        "            y_pred = model_lenet5(X)\n",
        "            validation_loss_sum += loss_fn(y_pred, y).item()\n",
        "            validation_accuracy_sum += accuracy(y_pred, y)\n",
        "\n",
        "        validation_loss     = validation_loss_sum / len(val_dataloader)\n",
        "        validation_accuracy = validation_accuracy_sum / len(val_dataloader)\n",
        "\n",
        "\n",
        "    writer.add_scalars(main_tag=\"Loss\", tag_scalar_dict={\"train/loss\": train_loss, \"val/loss\": validation_loss}, global_step=epoch)\n",
        "    writer.add_scalars(main_tag=\"Accuracy\", tag_scalar_dict={\"train/acc\": train_accuracy, \"val/acc\": validation_accuracy}, global_step=epoch)\n",
        "\n",
        "    print(f\"Epoch: {epoch}| Train loss: {train_loss: .5f}| Train acc: {train_accuracy: .5f}| Val loss: {validation_loss: .5f}| Val acc: {validation_accuracy: .5f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "5c91ff35ad344fbe807b15052b2ad926",
            "df955edc136a4fc18b91557be8e0746a",
            "4d569a2716f24b62aa7a7ffd3606bcbd",
            "5e579dd76c47463a8977dd791bd8d293",
            "312985adbd794f8d9f6f0ab2f4b8e771",
            "6de294ca8ec9406fa989ec45561d2dae",
            "d88755a344fe462abde7ef965b717cf5",
            "5955e19c593941628490b242d53472e6",
            "bf954290692b4cfd9ab744aa7ed62df7",
            "dffa0e80e69d4ba9ad1fb581b3c28ec8",
            "a047d8b8272d477dacce998ea7f0e7f2"
          ]
        },
        "id": "LhHWWURHmeiV",
        "outputId": "1b4cd731-cec8-4370-877f-9e69a5058243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c91ff35ad344fbe807b15052b2ad926"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0| Train loss:  0.16723| Train acc:  0.95205| Val loss:  0.08628| Val acc:  0.97523\n",
            "Epoch: 1| Train loss:  0.05366| Train acc:  0.98336| Val loss:  0.06327| Val acc:  0.98288\n",
            "Epoch: 2| Train loss:  0.03802| Train acc:  0.98823| Val loss:  0.05869| Val acc:  0.98255\n",
            "Epoch: 3| Train loss:  0.02903| Train acc:  0.99117| Val loss:  0.06092| Val acc:  0.98404\n",
            "Epoch: 4| Train loss:  0.02341| Train acc:  0.99235| Val loss:  0.05118| Val acc:  0.98637\n",
            "Epoch: 5| Train loss:  0.01809| Train acc:  0.99387| Val loss:  0.05497| Val acc:  0.98670\n",
            "Epoch: 6| Train loss:  0.01575| Train acc:  0.99482| Val loss:  0.05303| Val acc:  0.98687\n",
            "Epoch: 7| Train loss:  0.01320| Train acc:  0.99558| Val loss:  0.05526| Val acc:  0.98637\n",
            "Epoch: 8| Train loss:  0.01287| Train acc:  0.99558| Val loss:  0.05300| Val acc:  0.98703\n",
            "Epoch: 9| Train loss:  0.01039| Train acc:  0.99676| Val loss:  0.05850| Val acc:  0.98570\n",
            "Epoch: 10| Train loss:  0.01094| Train acc:  0.99628| Val loss:  0.06686| Val acc:  0.98471\n",
            "Epoch: 11| Train loss:  0.01122| Train acc:  0.99620| Val loss:  0.05917| Val acc:  0.98620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate test accuracy at the end of training**"
      ],
      "metadata": {
        "id": "e_ri-A53NBOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_lenet5.to(DEVICE_USED)\n",
        "model_lenet5.eval()\n",
        "\n",
        "with torch.inference_mode():\n",
        "    test_loss_sum, test_accuracy_sum = 0, 0\n",
        "    for X, y in test_dataloader:\n",
        "        X, y = X.to(DEVICE_USED), y.to(DEVICE_USED)\n",
        "        y_pred = model_lenet5(X)\n",
        "\n",
        "        test_loss_sum += loss_fn(y_pred, y)\n",
        "        test_accuracy_sum += accuracy(y_pred, y)\n",
        "\n",
        "    test_loss     = test_loss_sum / len(test_dataloader)\n",
        "    test_accuracy = test_accuracy_sum / len(test_dataloader)\n",
        "\n",
        "\n",
        "print(f\"Test loss: {test_loss: .5f}| Test accuracy: {test_accuracy: .5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA0Kah0NM9jN",
        "outputId": "d03427d8-44f9-4150-816a-bf878b6f134d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss:  0.04190| Test accuracy:  0.98942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model performance metrics"
      ],
      "metadata": {
        "id": "MeSMVLZyLGlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir={LOGGING_DIRECTORY}"
      ],
      "metadata": {
        "id": "rKHgvD4aLF3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving and loading of trained model"
      ],
      "metadata": {
        "id": "uqZTX0Z_KZiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "MODEL_NAME = \"lenet5_v1_mnist.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# Saving the model\n",
        "print(f\"Saving the model: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_lenet5.state_dict(), f=MODEL_SAVE_PATH)\n",
        "\n",
        "# Loading the saved model\n",
        "model_lenet5_v1_mnist_loaded = LeNet5Variant()\n",
        "model_lenet5_v1_mnist_loaded.load_state_dict(torch.load(MODEL_SAVE_PATH))"
      ],
      "metadata": {
        "id": "imfuKmnVnron"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}